<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="Kory.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Kory Illenye</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Teaching
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Class_2.html">STT 2810</a>
    </li>
    <li>
      <a href="Class_1.html">MAT 1110</a>
    </li>
    <li>
      <a href="Resources.html">Resources</a>
    </li>
    <li>
      <a href="Numerical_blog.html">Numerical Blog</a>
    </li>
  </ul>
</li>
<li>
  <a href="Contact.html">Contact</a>
</li>
<li>
  <a href="http://mathsci.appstate.edu">Department of Mathematical Sciences</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="steepest-descent-and-steepest-descent-with-least-squares." class="section level1">
<h1>Steepest Descent and Steepest Descent with Least Squares.</h1>
<p>Initially we started by looking at two iterative methods for finding solutions to positive definite, symmetric matrices. Steepest Descent is often called <strong>gradient descent</strong>, which is a approach to finding minima of a function <span class="math inline">\(f\)</span>. Using an estimate <span class="math inline">\(x_i\)</span>, the negative gradient <span class="math inline">\(-\nabla f(x_i)\)</span> gives the direction of in which <span class="math inline">\(f\)</span> is decreasing at the greatest rate. The goal is to take steps in this direction until we react the minimum.</p>
<p>Notation:</p>
<p><span class="math inline">\(e\)</span> denotes an error term</p>
<p><span class="math inline">\(i\)</span> denotes the i-ith term</p>
<p><span class="math inline">\(r\)</span> denotes a residual</p>
<p><span class="math display">\[e_i = x_i - x\]</span> <span class="math display">\[r_i = b - Ax_i = -Ae_i\]</span></p>
<p>To determine the size, often referred to as <span class="math inline">\(\alpha\)</span>, a ratio of inner products from residuals is used. <span class="math inline">\(x_{i+1} = x_i - \alpha_i\nabla f(x_i)\)</span> this minimizes <span class="math inline">\(f(x_{i+1})\)</span>. Now, that it is understood what is needed lets define a few things. To be symmetric</p>
<div id="creating-a-positive-definite-symetric-matrix" class="section level2">
<h2>Creating a positive definite, symetric matrix</h2>
<pre class="r"><code>#setting the seed to work with 
set.seed(31)
#Number of columns and rows in the matrix in the matrix
n &lt;- 5 
# Creates a Random matrix with n^2 randomly generated numbers
maxIts &lt;- 1000000
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A 
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>The return of TRUE from the code block above allows us to know that the matrix is positive definite. This means that the matrix has all positive eigen values. Now that all the components have been created for the use in the function. Lets see what the matrix looks like and design the function.</p>
<div id="the-matrix-a" class="section level3">
<h3>The Matrix A</h3>
<pre class="r"><code>#prints the matrix A
A</code></pre>
<pre><code>          [,1]      [,2]      [,3]      [,4]      [,5]
[1,] 2.4299775 1.7269373 2.0199944 0.5590044 1.5099956
[2,] 1.7269373 1.8590925 1.1651029 0.4614977 1.1855963
[3,] 2.0199944 1.1651029 1.8962176 0.5224703 1.2304534
[4,] 0.5590044 0.4614977 0.5224703 0.3137412 0.4209155
[5,] 1.5099956 1.1855963 1.2304534 0.4209155 1.0294046</code></pre>
</div>
<div id="the-b-vector" class="section level3">
<h3>The b vector</h3>
<pre class="r"><code>#Prints b
b</code></pre>
<pre><code>          [,1]
[1,] 2.2159566
[2,] 1.4658554
[3,] 1.9866331
[4,] 0.6013222
[5,] 1.3916532</code></pre>
</div>
</div>
</div>
<div id="the-funtion-of-gradient-descent-method" class="section level1">
<h1>The Funtion of Gradient Descent Method</h1>
<pre class="r"><code># defines the function
grad &lt;- function (A,b,x0, maxIts, tol)
  {
    # creates an initial residual
    r &lt;- b - (A %*% x0)
    # used to keep track of the number of iterations.
    k = 0
    # loop used to attempt to find the approximation of the X vector
    while (k &lt; maxIts &amp;&amp; norm(r, &quot;1&quot;) &gt; tol)
    {
      # increments the iteration
      k &lt;- k+1
      # creates a step size using the residuals and matrix A
      alpha &lt;- (t(r) %*% r) / (t(r) %*% (A %*% r))
      # creates the next approximation of the X vector
      x0 &lt;- x0 + drop(alpha) * r
      # creates the new residual with the new approximation
      r &lt;- b - A %*% x0
    }
  #Calculates the residual vector.
  res &lt;- x - x0
  # vairable to store the exact X, the aproximated X and the number of iterations
  sol &lt;- cbind(x, x0, res, matrix(rep(k,n),ncol = 1))
  # Names the colums of the new array
  colnames(sol) &lt;- c(&quot;X&quot;, &quot;X0&quot;,&quot;resid&quot;, &quot;iter&quot;)
  # prints the array
  sol
 
}</code></pre>
<p>This code when run generates the following:</p>
<pre class="r"><code># runs the function and saves it to a variable &quot;c&quot;
c &lt;- grad(A, b, x0, maxIts, tol)
# prints the array 
c </code></pre>
<pre><code>              X         X0         resid iter
[1,] 0.04876597 0.04895561 -1.896346e-04  325
[2,] 0.14752424 0.14746647  5.776931e-05  325
[3,] 0.81504717 0.81491134  1.358297e-04  325
[4,] 0.16098630 0.16109232 -1.060204e-04  325
[5,] 0.07040319 0.07030940  9.378641e-05  325</code></pre>
<p>I set the seed so this data can be replicated. As you can see the approximation is very close to the actual solution. The norm of the residual is 10^{-5} when rounded to 5 decimal places. For this document we know that if the <code>iter</code> column is not equal to `r maxits</p>
</div>
<div id="x6-matrix" class="section level1">
<h1>6x6 matrix</h1>
<pre class="r"><code>set.seed(21)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>Lets see how the function does on this 6x6 matrix.</p>
<pre class="r"><code>sol&lt;-grad(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>             X        X0         resid iter
[1,] 0.2163319 0.2164881 -0.0001561833 1781
[2,] 0.6504235 0.6502254  0.0001980371 1781
[3,] 0.3351660 0.3348874  0.0002786669 1781
[4,] 0.5076559 0.5075127  0.0001432318 1781
[5,] 0.6528394 0.6532767 -0.0004373487 1781
[6,] 0.9655767 0.9654451  0.0001315399 1781</code></pre>
<p>I want to look at a few matrices, I am going to adjust the seed number for each. These numbers are arbitrary but for replication purposes I am setting the seed.</p>
<pre class="r"><code>set.seed(214)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>Lets see how the function does on this 6x6 matrix.</p>
<pre class="r"><code>A</code></pre>
<pre><code>         [,1]     [,2]      [,3]      [,4]      [,5]      [,6]
[1,] 2.591707 2.217206 1.1814162 1.5399616 1.6181376 1.1860408
[2,] 2.217206 2.650669 1.6894440 2.0397363 1.4540539 1.1738115
[3,] 1.181416 1.689444 1.3483715 1.3084386 0.9020424 0.5422738
[4,] 1.539962 2.039736 1.3084386 2.0160104 1.2108004 0.8519311
[5,] 1.618138 1.454054 0.9020424 1.2108004 1.4474137 0.4330670
[6,] 1.186041 1.173812 0.5422738 0.8519311 0.4330670 0.9206222</code></pre>
<pre class="r"><code>sol &lt;-grad(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>             X        X0         resid iter
[1,] 0.6807363 0.6806130  1.233517e-04 1419
[2,] 0.1331188 0.1331240 -5.250738e-06 1419
[3,] 0.4157805 0.4157955 -1.500242e-05 1419
[4,] 0.8683657 0.8683055  6.016602e-05 1419
[5,] 0.6214230 0.6215572 -1.341803e-04 1419
[6,] 0.1328657 0.1330050 -1.392501e-04 1419</code></pre>
<p>We can see that the function completed after 1419 iterations. This means that the norm is within <span class="math inline">\(10^{-5}\)</span>.</p>
<pre class="r"><code>set.seed(2145)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>Lets see how the function does on this 6x6 matrix.</p>
<pre class="r"><code>A</code></pre>
<pre><code>         [,1]      [,2]      [,3]     [,4]     [,5]     [,6]
[1,] 1.629180 1.3253076 1.3704596 1.897338 1.492470 1.388390
[2,] 1.325308 2.1268329 0.9046964 2.031244 1.432492 1.145834
[3,] 1.370460 0.9046964 1.6388220 1.852486 1.570883 1.469332
[4,] 1.897338 2.0312444 1.8524862 2.844479 2.251959 1.748982
[5,] 1.492470 1.4324924 1.5708827 2.251959 2.753722 1.775626
[6,] 1.388390 1.1458340 1.4693319 1.748982 1.775626 1.692876</code></pre>
<pre class="r"><code>sol&lt;- grad(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>             X        X0         resid iter
[1,] 0.6258299 0.6258653 -3.544603e-05 1515
[2,] 0.2011419 0.2014055 -2.636294e-04 1515
[3,] 0.5883483 0.5887837 -4.354756e-04 1515
[4,] 0.8560448 0.8556266  4.181889e-04 1515
[5,] 0.9363852 0.9364996 -1.144587e-04 1515
[6,] 0.9780356 0.9777614  2.741660e-04 1515</code></pre>
<p>We can see that the function completed after 1515 iterations. This means that the norm is within <span class="math inline">\(10^{-5}\)</span>.</p>
<pre class="r"><code>set.seed(21456)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>Lets see how the function does on this 6x6 matrix.</p>
<pre class="r"><code>A</code></pre>
<pre><code>          [,1]      [,2]     [,3]      [,4]      [,5]      [,6]
[1,] 2.5322214 0.9122529 2.004203 1.5482151 0.7751318 2.0283032
[2,] 0.9122529 2.0519766 2.134736 0.9660084 0.7108958 1.5908699
[3,] 2.0042025 2.1347358 3.714131 1.4712356 1.1478843 2.0035704
[4,] 1.5482151 0.9660084 1.471236 1.2711860 0.6324079 1.4763406
[5,] 0.7751318 0.7108958 1.147884 0.6324079 0.4117123 0.7575121
[6,] 2.0283032 1.5908699 2.003570 1.4763406 0.7575121 2.3369386</code></pre>
<pre class="r"><code>sol&lt;- grad(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>              X         X0         resid iter
[1,] 0.79899443 0.79902045 -2.601344e-05 2127
[2,] 0.43135773 0.43143786 -8.012212e-05 2127
[3,] 0.07193685 0.07209572 -1.588676e-04 2127
[4,] 0.10669362 0.10699923 -3.056067e-04 2127
[5,] 0.33782973 0.33693283  8.969094e-04 2127
[6,] 0.15723681 0.15712123  1.155732e-04 2127</code></pre>
<p>We can see that the function completed after 2127 iterations. This means that the norm is within <span class="math inline">\(10^{-5}\)</span>.</p>
</div>
<div id="x10-matrix" class="section level1">
<h1>10x10 matrix</h1>
<pre class="r"><code>set.seed(21456)
n &lt;- 10 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>A</code></pre>
<pre><code>          [,1]     [,2]      [,3]     [,4]     [,5]      [,6]     [,7]
 [1,] 4.576307 3.544017 1.8706107 2.699453 3.464121 2.1412326 3.630429
 [2,] 3.544017 3.995759 1.7402252 2.908020 3.122860 1.7878213 3.701816
 [3,] 1.870611 1.740225 1.4091612 1.632820 1.585560 0.8950613 1.883202
 [4,] 2.699453 2.908020 1.6328204 3.177959 2.352454 1.6335524 2.982156
 [5,] 3.464121 3.122860 1.5855600 2.352454 3.832469 2.1929775 3.852252
 [6,] 2.141233 1.787821 0.8950613 1.633552 2.192978 2.0398368 2.512283
 [7,] 3.630429 3.701816 1.8832023 2.982156 3.852252 2.5122828 5.087222
 [8,] 2.783155 2.232120 1.2940313 1.823810 2.891021 1.8346436 3.536088
 [9,] 2.300886 2.567662 1.2002483 2.224262 2.623019 1.8329427 3.223934
[10,] 2.345922 2.103801 1.4733256 1.801321 2.664459 1.7837057 2.810596
          [,8]     [,9]    [,10]
 [1,] 2.783155 2.300886 2.345922
 [2,] 2.232120 2.567662 2.103801
 [3,] 1.294031 1.200248 1.473326
 [4,] 1.823810 2.224262 1.801321
 [5,] 2.891021 2.623019 2.664459
 [6,] 1.834644 1.832943 1.783706
 [7,] 3.536088 3.223934 2.810596
 [8,] 3.133619 2.283068 1.976192
 [9,] 2.283068 2.591424 1.922565
[10,] 1.976192 1.922565 2.373093</code></pre>
<pre class="r"><code>sol&lt;- grad(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>              X        X0         resid iter
 [1,] 0.6172931 0.6173013 -8.226232e-06 3532
 [2,] 0.8323071 0.8323258 -1.870730e-05 3532
 [3,] 0.5397727 0.5397052  6.745871e-05 3532
 [4,] 0.1785781 0.1785965 -1.844572e-05 3532
 [5,] 0.7888260 0.7887850  4.097310e-05 3532
 [6,] 0.3950113 0.3949807  3.059918e-05 3532
 [7,] 0.7050482 0.7050369  1.135881e-05 3532
 [8,] 0.8651250 0.8651531 -2.812421e-05 3532
 [9,] 0.1558820 0.1558699  1.212071e-05 3532
[10,] 0.3583763 0.3584488 -7.249651e-05 3532</code></pre>
<p>We can see that the function completed after 3532 iterations. This means that the norm is within <span class="math inline">\(10^{-5}\)</span>.</p>
</div>
<div id="gradient-descent-with-least-squares" class="section level1">
<h1>Gradient Descent with least squares</h1>
<p>This function is supposed to converge faster.</p>
<pre class="r"><code># defines the function
gradLS &lt;- function (A,b,x0, maxIts, tol)
  {
    # creates an initial residual
    r &lt;- b - (A %*% x0)
    # used to keep track of the number of iterations.
    k = 0
    # loop used to attempt to find the approximation of the X vector
    while (k &lt; maxIts &amp;&amp; norm(r, &quot;1&quot;) &gt; tol)
    {
      # increments the iteration
      k &lt;- k+1
      # creates a step size using the residuals and matrix A
      alpha &lt;- (t(r) %*% r) / (t(A%*%r) %*% (A %*% r))
      # creates the next approximation of the X vector
      x0 &lt;- x0 + drop(alpha) * r
      # creates the new residual with the new approximation
      r &lt;- t(A)%*% b - (t(A) %*% A) %*% x0
    }
  #Calculates the residual vector.
  res &lt;- x - x0
  # vairable to store the exact X, the aproximated X and the number of iterations
  sol &lt;- cbind(x, x0, res, matrix(rep(k,n),ncol = 1))
  # Names the colums of the new array
  colnames(sol) &lt;- c(&quot;X&quot;, &quot;X0&quot;,&quot;resid&quot;, &quot;iter&quot;)
  # prints the array
  sol
 
}</code></pre>
<pre class="r"><code>A</code></pre>
<pre><code>          [,1]     [,2]      [,3]     [,4]     [,5]      [,6]     [,7]
 [1,] 4.576307 3.544017 1.8706107 2.699453 3.464121 2.1412326 3.630429
 [2,] 3.544017 3.995759 1.7402252 2.908020 3.122860 1.7878213 3.701816
 [3,] 1.870611 1.740225 1.4091612 1.632820 1.585560 0.8950613 1.883202
 [4,] 2.699453 2.908020 1.6328204 3.177959 2.352454 1.6335524 2.982156
 [5,] 3.464121 3.122860 1.5855600 2.352454 3.832469 2.1929775 3.852252
 [6,] 2.141233 1.787821 0.8950613 1.633552 2.192978 2.0398368 2.512283
 [7,] 3.630429 3.701816 1.8832023 2.982156 3.852252 2.5122828 5.087222
 [8,] 2.783155 2.232120 1.2940313 1.823810 2.891021 1.8346436 3.536088
 [9,] 2.300886 2.567662 1.2002483 2.224262 2.623019 1.8329427 3.223934
[10,] 2.345922 2.103801 1.4733256 1.801321 2.664459 1.7837057 2.810596
          [,8]     [,9]    [,10]
 [1,] 2.783155 2.300886 2.345922
 [2,] 2.232120 2.567662 2.103801
 [3,] 1.294031 1.200248 1.473326
 [4,] 1.823810 2.224262 1.801321
 [5,] 2.891021 2.623019 2.664459
 [6,] 1.834644 1.832943 1.783706
 [7,] 3.536088 3.223934 2.810596
 [8,] 3.133619 2.283068 1.976192
 [9,] 2.283068 2.591424 1.922565
[10,] 1.976192 1.922565 2.373093</code></pre>
<pre class="r"><code>sol&lt;- gradLS(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>              X        X0         resid   iter
 [1,] 0.6172931 0.6177202 -0.0004271701 914619
 [2,] 0.8323071 0.8332761 -0.0009690351 914619
 [3,] 0.5397727 0.5362854  0.0034873060 914619
 [4,] 0.1785781 0.1795333 -0.0009552130 914619
 [5,] 0.7888260 0.7867091  0.0021169184 914619
 [6,] 0.3950113 0.3934302  0.0015811167 914619
 [7,] 0.7050482 0.7044629  0.0005853126 914619
 [8,] 0.8651250 0.8665807 -0.0014557269 914619
 [9,] 0.1558820 0.1552567  0.0006253598 914619
[10,] 0.3583763 0.3621263 -0.0037499883 914619</code></pre>
<p>Here is the point my mind went, What!!!! This took 9.1461910^{5} iterations. Why? I had to know more. initially I decided lets mess with the code a little.</p>
<p>So on the line that creates the new residual I removed the additional transposes of A.</p>
<pre class="r"><code># defines the function
gradLS2 &lt;- function (A,b,x0, maxIts, tol)
  {
    # creates an initial residual
    r &lt;- b - (A %*% x0)
    # used to keep track of the number of iterations.
    k = 0
    # loop used to attempt to find the approximation of the X vector
    while (k &lt; maxIts &amp;&amp; norm(r, &quot;1&quot;) &gt; tol)
    {
      # increments the iteration
      k &lt;- k+1
      # creates a step size using the residuals and matrix A
      alpha &lt;- (t(r) %*% r) / (t(A%*%r) %*% (A %*% r))
      # creates the next approximation of the X vector
      x0 &lt;- x0 + drop(alpha) * r
      # creates the new residual with the new approximation
      r &lt;-  b - (A) %*% x0
    }
  #Calculates the residual vector.
  res &lt;- x - x0
  # vairable to store the exact X, the aproximated X and the number of iterations
  sol &lt;- cbind(x, x0, res, matrix(rep(k,n),ncol = 1))
  # Names the colums of the new array
  colnames(sol) &lt;- c(&quot;X&quot;, &quot;X0&quot;,&quot;resid&quot;, &quot;iter&quot;)
  # prints the array
  sol
 
}</code></pre>
<p>Same matrix but slightly different function</p>
<pre class="r"><code>A</code></pre>
<pre><code>          [,1]     [,2]      [,3]     [,4]     [,5]      [,6]     [,7]
 [1,] 4.576307 3.544017 1.8706107 2.699453 3.464121 2.1412326 3.630429
 [2,] 3.544017 3.995759 1.7402252 2.908020 3.122860 1.7878213 3.701816
 [3,] 1.870611 1.740225 1.4091612 1.632820 1.585560 0.8950613 1.883202
 [4,] 2.699453 2.908020 1.6328204 3.177959 2.352454 1.6335524 2.982156
 [5,] 3.464121 3.122860 1.5855600 2.352454 3.832469 2.1929775 3.852252
 [6,] 2.141233 1.787821 0.8950613 1.633552 2.192978 2.0398368 2.512283
 [7,] 3.630429 3.701816 1.8832023 2.982156 3.852252 2.5122828 5.087222
 [8,] 2.783155 2.232120 1.2940313 1.823810 2.891021 1.8346436 3.536088
 [9,] 2.300886 2.567662 1.2002483 2.224262 2.623019 1.8329427 3.223934
[10,] 2.345922 2.103801 1.4733256 1.801321 2.664459 1.7837057 2.810596
          [,8]     [,9]    [,10]
 [1,] 2.783155 2.300886 2.345922
 [2,] 2.232120 2.567662 2.103801
 [3,] 1.294031 1.200248 1.473326
 [4,] 1.823810 2.224262 1.801321
 [5,] 2.891021 2.623019 2.664459
 [6,] 1.834644 1.832943 1.783706
 [7,] 3.536088 3.223934 2.810596
 [8,] 3.133619 2.283068 1.976192
 [9,] 2.283068 2.591424 1.922565
[10,] 1.976192 1.922565 2.373093</code></pre>
<pre class="r"><code>sol&lt;- gradLS2(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>              X        X0         resid iter
 [1,] 0.6172931 0.6173075 -1.444088e-05  886
 [2,] 0.8323071 0.8322895  1.756001e-05  886
 [3,] 0.5397727 0.5397693  3.335324e-06  886
 [4,] 0.1785781 0.1785764  1.682705e-06  886
 [5,] 0.7888260 0.7888242  1.814743e-06  886
 [6,] 0.3950113 0.3949988  1.251022e-05  886
 [7,] 0.7050482 0.7050616 -1.332729e-05  886
 [8,] 0.8651250 0.8651073  1.765960e-05  886
 [9,] 0.1558820 0.1558986 -1.654262e-05  886
[10,] 0.3583763 0.3583780 -1.650070e-06  886</code></pre>
<p>Well, that’s weird 886 iterations. This seems interesting we went from 3532 to 914619 to 886 iterations. Well this fixed the problem for this matrix but does it work for all?</p>
<pre class="r"><code>set.seed(214567)
n &lt;- 5
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>A</code></pre>
<pre><code>          [,1]     [,2]      [,3]      [,4]      [,5]
[1,] 1.3951977 1.439403 0.9458712 0.6875470 0.3530277
[2,] 1.4394026 2.826384 2.1103633 1.3952379 1.3081469
[3,] 0.9458712 2.110363 1.8090746 0.9263186 1.1690460
[4,] 0.6875470 1.395238 0.9263186 0.8325923 0.6920785
[5,] 0.3530277 1.308147 1.1690460 0.6920785 1.0185438</code></pre>
<pre class="r"><code>sol1&lt;- grad(A, b, x0, maxIts, tol)
sol2&lt;- gradLS(A, b, x0, maxIts, tol)
sol3&lt;- gradLS2(A, b, x0, maxIts, tol)
sol1</code></pre>
<pre><code>              X         X0         resid iter
[1,] 0.28642738 0.28633495  9.243224e-05 4667
[2,] 0.09199288 0.09073066  1.262219e-03 4667
[3,] 0.36928209 0.37065175 -1.369664e-03 4667
[4,] 0.03981780 0.04120865 -1.390849e-03 4667
[5,] 0.95860400 0.95773918  8.648254e-04 4667</code></pre>
<pre class="r"><code>sol2</code></pre>
<pre><code>              X          X0        resid iter
[1,] 0.28642738 0.280137231  0.006290151  486
[2,] 0.09199288 0.008120223  0.083872660  486
[3,] 0.36928209 0.460459605 -0.091177516  486
[4,] 0.03981780 0.132354278 -0.092536480  486
[5,] 0.95860400 0.900839980  0.057764024  486</code></pre>
<pre class="r"><code>sol3</code></pre>
<pre><code>              X         X0         resid iter
[1,] 0.28642738 0.28639605  3.133395e-05 1439
[2,] 0.09199288 0.09156893  4.239535e-04 1439
[3,] 0.36928209 0.36974119 -4.591008e-04 1439
[4,] 0.03981780 0.04028413 -4.663322e-04 1439
[5,] 0.95860400 0.95831367  2.903382e-04 1439</code></pre>
<p>Well this matrix broke my theory again. Back to the drawing board. I decided maybe I just had a bad pseudo code. I decided to look into another iterative method and found the advanced chevy cheb iterative method that avoids dot products of residuals.</p>
</div>
<div id="advanced-cheby-chev-iterative-method" class="section level1">
<h1>Advanced Cheby Chev iterative method</h1>
<p>So I did some research and found some pseudo code to play with.</p>
<pre class="r"><code>cheby &lt;- function (A,b,x0, maxIts, tol)
{
  ev &lt;- eigen(A)
  lmax&lt;- max(ev$values)
  lmin &lt;- min(ev$values)
  
  d&lt;- (lmax +lmin)/2.0
  c&lt;- (lmax-lmin)/2.0
  precon &lt;- diag(length(A[,1]))
  x &lt;- x0
  r &lt;- b - A %*% x
  i &lt;- 1
  while(i &lt; maxIts &amp;&amp; norm(r, &quot;1&quot;) &gt; tol)
  {
    z = solve(precon, r)
    if (i == 1)
    {
      p &lt;- z
      alpha &lt;- 1/d
    }
    else
    {
      beta &lt;- (c*alpha/2.0)^2
      alpha &lt;- 1/(d-beta/alpha)
      p &lt;- z + beta*p
    }
    x &lt;- x + alpha*p
    r &lt;- b - A %*% x
    i = i+1
  }
  #Calculates the residual vector.
  res &lt;- x - x0
  # vairable to store the exact X, the aproximated X and the number of iterations
  sol &lt;- cbind(x, x0, res, matrix(rep(i-1,n),ncol = 1))
  # Names the colums of the new array
  colnames(sol) &lt;- c(&quot;X&quot;, &quot;X0&quot;,&quot;resid&quot;, &quot;iter&quot;)
  # prints the array
  sol
}</code></pre>
<p>lets see how it does?</p>
<pre class="r"><code>A</code></pre>
<pre><code>          [,1]     [,2]      [,3]      [,4]      [,5]
[1,] 1.3951977 1.439403 0.9458712 0.6875470 0.3530277
[2,] 1.4394026 2.826384 2.1103633 1.3952379 1.3081469
[3,] 0.9458712 2.110363 1.8090746 0.9263186 1.1690460
[4,] 0.6875470 1.395238 0.9263186 0.8325923 0.6920785
[5,] 0.3530277 1.308147 1.1690460 0.6920785 1.0185438</code></pre>
<pre class="r"><code>sol1&lt;- grad(A, b, x0, maxIts, tol)
sol2&lt;- gradLS(A, b, x0, maxIts, tol)
sol3&lt;- gradLS2(A, b, x0, maxIts, tol)
sol4&lt;- cheby(A, b, x0, maxIts, tol)
sol1</code></pre>
<pre><code>              X         X0         resid iter
[1,] 0.28642738 0.28633495  9.243224e-05 4667
[2,] 0.09199288 0.09073066  1.262219e-03 4667
[3,] 0.36928209 0.37065175 -1.369664e-03 4667
[4,] 0.03981780 0.04120865 -1.390849e-03 4667
[5,] 0.95860400 0.95773918  8.648254e-04 4667</code></pre>
<pre class="r"><code>sol2</code></pre>
<pre><code>              X          X0        resid iter
[1,] 0.28642738 0.280137231  0.006290151  486
[2,] 0.09199288 0.008120223  0.083872660  486
[3,] 0.36928209 0.460459605 -0.091177516  486
[4,] 0.03981780 0.132354278 -0.092536480  486
[5,] 0.95860400 0.900839980  0.057764024  486</code></pre>
<pre class="r"><code>sol3</code></pre>
<pre><code>              X         X0         resid iter
[1,] 0.28642738 0.28639605  3.133395e-05 1439
[2,] 0.09199288 0.09156893  4.239535e-04 1439
[3,] 0.36928209 0.36974119 -4.591008e-04 1439
[4,] 0.03981780 0.04028413 -4.663322e-04 1439
[5,] 0.95860400 0.95831367  2.903382e-04 1439</code></pre>
<pre class="r"><code>sol4</code></pre>
<pre><code>              X X0      resid iter
[1,] 0.28642714  0 0.28642714  496
[2,] 0.09199234  0 0.09199234  496
[3,] 0.36928183  0 0.36928183  496
[4,] 0.03981767  0 0.03981767  496
[5,] 0.95860372  0 0.95860372  496</code></pre>
<p>Interesting this matrix it only took 496 iterations. Lets try a few more from earlier.</p>
<pre class="r"><code>set.seed(21456)
n &lt;- 10 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>A</code></pre>
<pre><code>          [,1]     [,2]      [,3]     [,4]     [,5]      [,6]     [,7]
 [1,] 4.576307 3.544017 1.8706107 2.699453 3.464121 2.1412326 3.630429
 [2,] 3.544017 3.995759 1.7402252 2.908020 3.122860 1.7878213 3.701816
 [3,] 1.870611 1.740225 1.4091612 1.632820 1.585560 0.8950613 1.883202
 [4,] 2.699453 2.908020 1.6328204 3.177959 2.352454 1.6335524 2.982156
 [5,] 3.464121 3.122860 1.5855600 2.352454 3.832469 2.1929775 3.852252
 [6,] 2.141233 1.787821 0.8950613 1.633552 2.192978 2.0398368 2.512283
 [7,] 3.630429 3.701816 1.8832023 2.982156 3.852252 2.5122828 5.087222
 [8,] 2.783155 2.232120 1.2940313 1.823810 2.891021 1.8346436 3.536088
 [9,] 2.300886 2.567662 1.2002483 2.224262 2.623019 1.8329427 3.223934
[10,] 2.345922 2.103801 1.4733256 1.801321 2.664459 1.7837057 2.810596
          [,8]     [,9]    [,10]
 [1,] 2.783155 2.300886 2.345922
 [2,] 2.232120 2.567662 2.103801
 [3,] 1.294031 1.200248 1.473326
 [4,] 1.823810 2.224262 1.801321
 [5,] 2.891021 2.623019 2.664459
 [6,] 1.834644 1.832943 1.783706
 [7,] 3.536088 3.223934 2.810596
 [8,] 3.133619 2.283068 1.976192
 [9,] 2.283068 2.591424 1.922565
[10,] 1.976192 1.922565 2.373093</code></pre>
<pre class="r"><code>sol&lt;- cheby(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>              X X0     resid iter
 [1,] 0.6172931  0 0.6172931  325
 [2,] 0.8323071  0 0.8323071  325
 [3,] 0.5397727  0 0.5397727  325
 [4,] 0.1785781  0 0.1785781  325
 [5,] 0.7888260  0 0.7888260  325
 [6,] 0.3950113  0 0.3950113  325
 [7,] 0.7050483  0 0.7050483  325
 [8,] 0.8651250  0 0.8651250  325
 [9,] 0.1558820  0 0.1558820  325
[10,] 0.3583763  0 0.3583763  325</code></pre>
<p>wow, on the 10x10 it only took 325 iterations!</p>
<pre class="r"><code>set.seed(21456)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>Lets see how the function does on this 6x6 matrix.</p>
<pre class="r"><code>A</code></pre>
<pre><code>          [,1]      [,2]     [,3]      [,4]      [,5]      [,6]
[1,] 2.5322214 0.9122529 2.004203 1.5482151 0.7751318 2.0283032
[2,] 0.9122529 2.0519766 2.134736 0.9660084 0.7108958 1.5908699
[3,] 2.0042025 2.1347358 3.714131 1.4712356 1.1478843 2.0035704
[4,] 1.5482151 0.9660084 1.471236 1.2711860 0.6324079 1.4763406
[5,] 0.7751318 0.7108958 1.147884 0.6324079 0.4117123 0.7575121
[6,] 2.0283032 1.5908699 2.003570 1.4763406 0.7575121 2.3369386</code></pre>
<pre class="r"><code>sol&lt;- cheby(A, b, x0, maxIts, tol)
sol</code></pre>
<pre><code>              X X0      resid iter
[1,] 0.79899462  0 0.79899462  393
[2,] 0.43135791  0 0.43135791  393
[3,] 0.07193712  0 0.07193712  393
[4,] 0.10669381  0 0.10669381  393
[5,] 0.33782969  0 0.33782969  393
[6,] 0.15723699  0 0.15723699  393</code></pre>
<p>Even better for this 6x6! Well what is different between gradient descent and cheby chevy. Well Cheby Chevy iteration avoids the dot products and ratio of residuals. It uses an elliptical approach to solving the problem. This means we have to have some knowledge of the eigen values of our matrix.</p>
<p>After talking to Dr. Palmer I realized that part of the problem might be that the matrices are ill conditioned. So, lets redefine a few matrices and look at the condition numbers.</p>
<pre class="r"><code>set.seed(21456)
n &lt;- 10 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
A &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- A %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(A)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>set.seed(2145)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
B &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- B %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(B)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>set.seed(214)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
C &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- C %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(C)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>set.seed(21)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
D &lt;- t(A) %*% A
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- D %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(D)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>kappa(A)</code></pre>
<pre><code>[1] 49.10724</code></pre>
<pre class="r"><code>kappa(B)</code></pre>
<pre><code>[1] 2148.086</code></pre>
<pre class="r"><code>kappa(C)</code></pre>
<pre><code>[1] 434.2473</code></pre>
<pre class="r"><code>kappa(D)</code></pre>
<pre><code>[1] 1706.385</code></pre>
<p>Well higher condition numbers mean that the matrices are ill conditioned. We can see that matrix B is highly ill conditioned. Well lets condition a matrix and see how that affects the number of iterations. We can use the B matrix.</p>
<pre class="r"><code>set.seed(2145)
n &lt;- 6 
# Creates a Random matrix with n^2 randomly generated numbers
A&lt;-matrix(runif(n^2), ncol=n)
# Forces the matrix to be symmetric
B &lt;- (t(A) %*% A)
B&lt;- B + (100*diag(n))
# Creates a random solution vector to solve for
x &lt;- matrix(runif(n), ncol = 1)
# Creates a b vector from our random vector x
b &lt;- B %*% x
# initial approximation vector (zero vecor)
x0 &lt;- matrix(rep(0.0,n), ncol = 1)
# Setting a tolerance for the norm of our vector
tol = 10^-5
# determines if all the eigen values are positive
is.positive.definite(B)</code></pre>
<pre><code>[1] TRUE</code></pre>
<pre class="r"><code>B</code></pre>
<pre><code>           [,1]        [,2]        [,3]       [,4]       [,5]       [,6]
[1,] 101.629180   1.3253076   1.3704596   1.897338   1.492470   1.388390
[2,]   1.325308 102.1268329   0.9046964   2.031244   1.432492   1.145834
[3,]   1.370460   0.9046964 101.6388220   1.852486   1.570883   1.469332
[4,]   1.897338   2.0312444   1.8524862 102.844479   2.251959   1.748982
[5,]   1.492470   1.4324924   1.5708827   2.251959 102.753722   1.775626
[6,]   1.388390   1.1458340   1.4693319   1.748982   1.775626 101.692876</code></pre>
<pre class="r"><code>sol1&lt;- grad(B, b, x0, maxIts, tol)
sol2&lt;- gradLS(B, b, x0, maxIts, tol)
sol3&lt;- gradLS2(B, b, x0, maxIts, tol)
sol4&lt;- cheby(B, b, x0, maxIts, tol)
sol1</code></pre>
<pre><code>             X        X0         resid iter
[1,] 0.6258299 0.6258299 -3.726958e-09    5
[2,] 0.2011419 0.2011419 -1.359563e-08    5
[3,] 0.5883483 0.5883483 -2.515808e-08    5
[4,] 0.8560448 0.8560448  6.611190e-09    5
[5,] 0.9363852 0.9363852 -1.016239e-08    5
[6,] 0.9780356 0.9780356  1.431781e-08    5</code></pre>
<pre class="r"><code>sol2</code></pre>
<pre><code>             X        X0        resid iter
[1,] 0.6258299 0.6258299 6.393130e-11    9
[2,] 0.2011419 0.2011419 3.926945e-11    9
[3,] 0.5883483 0.5883483 1.334466e-11    9
[4,] 0.8560448 0.8560448 1.281852e-10    9
[5,] 0.9363852 0.9363852 6.868373e-11    9
[6,] 0.9780356 0.9780356 1.035089e-10    9</code></pre>
<pre class="r"><code>sol3</code></pre>
<pre><code>             X        X0         resid iter
[1,] 0.6258299 0.6258299  8.458740e-09 1880
[2,] 0.2011419 0.2011419 -1.867218e-08 1880
[3,] 0.5883483 0.5883482  4.345919e-09 1880
[4,] 0.8560448 0.8560448  1.170221e-08 1880
[5,] 0.9363852 0.9363851  1.918453e-08 1880
[6,] 0.9780356 0.9780356  3.216321e-08 1880</code></pre>
<pre class="r"><code>sol4</code></pre>
<pre><code>             X X0     resid iter
[1,] 0.6258299  0 0.6258299    6
[2,] 0.2011419  0 0.2011419    6
[3,] 0.5883483  0 0.5883483    6
[4,] 0.8560448  0 0.8560448    6
[5,] 0.9363852  0 0.9363852    6
[6,] 0.9780356  0 0.9780356    6</code></pre>
<p>By conditioning the matrix prior to solving using the iterative method we can see that it makes a significant difference in solving for the solution but Cheby Chev’s method is still close to the fastest method for solving these symmetric matrices. There is also a functional form that can be used for non-symmetric matrices. I want to consider using this on image processing and seeing where this takes me.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
